{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbcb247a",
   "metadata": {},
   "source": [
    "# OpenCV Face Recognition\n",
    "\n",
    "This script uses OpenCV and Dlib's pre-trained models to recognize faces in real-time through a webcam feed.  \n",
    "The program captures video from the webcam, detects faces, and then compares them with known faces stored in a local dataset.  \n",
    "If a match is found, the name of the recognized individual is displayed. If no match is found, it shows \"Unknown.\"\n",
    "\n",
    "## How it works:\n",
    "- Captures frames from the webcam.\n",
    "- Detects faces using Dlib's face detector.\n",
    "- Encodes the faces and compares them with a known dataset of face encodings.\n",
    "- Displays the name of the recognized person or \"Unknown\" if no match is found.\n",
    "- Draws a rectangle around the detected faces and labels them with the name.\n",
    "\n",
    "Press 'q' to exit the webcam feed.\n",
    "\n",
    "## Prerequisites:\n",
    "1. Pre-trained models (Dlib's shape predictor and face recognition models) should be downloaded and placed in the `models/` folder.\n",
    "2. Known faces (images) should be stored in the `dataset/` folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe5b44b-86a0-4e7d-84e4-7908437288c8",
   "metadata": {},
   "source": [
    "## Kütüphaneleri İçeri Aktar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc88ceff-ce9e-4545-8419-11562097fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cece18-2b7e-4138-9efc-9fa6555efdaa",
   "metadata": {},
   "source": [
    "## Yüz tanıma modeli yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55312327-0bb3-4f4a-92b1-d40ebf18450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained face landmark detector from Dlib\n",
    "# Shape predictor is used to detect facial landmarks (e.g. eyes, nose, mouth)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "sp = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  # Landmark modeli\n",
    "\n",
    "# Load the pre-trained face recognition model from Dlib\n",
    "facerec = dlib.face_recognition_model_v1(\"dlib_face_recognition_resnet_model_v1.dat\")  # Yüz tanıma modeli\n",
    "\n",
    "# Kişileri ve yüz özelliklerini saklayacak dictionary\n",
    "known_faces = {}\n",
    "dataset_path = \"dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049d43fc-5b0d-4b3d-9566-0dec88e26b36",
   "metadata": {},
   "source": [
    "## Dataset klasöründeki yüzleri tanı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c742408d-5e31-403e-a55b-f2f459655373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset'teki her yüzü tanıt\n",
    "for filename in os.listdir(dataset_path):\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    img_path = os.path.join(dataset_path, filename)\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "     # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the frame\n",
    "    faces = detector(gray)\n",
    "    if len(faces) > 0:\n",
    "        shape = sp(img, faces[0])  # İlk yüzü al\n",
    "        face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
    "        known_faces[name] = np.array(face_descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2590ba2-1a3c-4c9b-8ad4-1a802b8d7f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc13d7e4-ff05-417d-8615-76db08433c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        shape = sp(frame, face)\n",
    "        face_descriptor = facerec.compute_face_descriptor(frame, shape)\n",
    "        face_descriptor = np.array(face_descriptor)\n",
    "\n",
    "        # Find the name of the matched face with the minimum distance\n",
    "        min_dist = float(\"inf\")\n",
    "        identity = \"Unknown\"\n",
    "\n",
    "        for name, known_face in known_faces.items():\n",
    "            dist = np.linalg.norm(known_face - face_descriptor)\n",
    "            if dist < 0.4:  # Threshold for recognition accuracy\n",
    "                min_dist = dist\n",
    "                identity = name\n",
    "\n",
    "        # İsmi ekrana yaz\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, identity, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):  # Break the loop if the user presses the 'q' key\n",
    "        break\n",
    "\n",
    "# Release the capture object and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050dd48-1a3c-4cae-88ea-ec78806015d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (py311)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
